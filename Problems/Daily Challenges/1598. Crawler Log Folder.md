[1598. Crawler Log Folder](https://leetcode.com/problems/crawler-log-folder/)

# Intuition

To solve the problem, we need to simulate navigating through the folder structure and keep track of the current depth from the main folder. By counting how many levels deep we go, we can then determine the number of steps needed to return to the main folder.

# Approach

1. Initialize a counter to keep track of the depth of the current folder.
2. Iterate through the logs:
   - If the log is `"../"`, decrement the counter if it's greater than 0 (to avoid going above the main folder).
   - If the log is `"./"`, do nothing as it means staying in the current folder.
   - If the log is a folder name (ending with `"/"`), increment the counter.
3. After processing all logs, the counter will represent the number of steps away from the main folder.
4. The result will be the value of the counter.

# Complexity

- **Time Complexity**: ***O(n)***, where *n* is the number of logs. We process each log once.
- **Space Complexity**: ***O(1)***, since we only use a counter to keep track of the depth.

# Code
```typescript
function minOperations(logs: string[]): number {
    let depth = 0;
    
    for (const log of logs) {
        if (log === "../") {
            if (depth > 0) {
                depth--;
            }
        } else if (log !== "./") {
            depth++;
        }
    }
    
    return depth;
};

```

### Explanation of the Code

1. **Initialization**: Start with `depth = 0` to represent the main folder.
2. **Iterate through Logs**: For each log, adjust the depth based on the operation:
   - `"../"`: Move up one level if possible (decrement depth if it's greater than 0).
   - `"./"`: Stay in the current folder (no change to depth).
   - Any other log (child folder): Move down one level (increment depth).
3. **Return Depth**: The final value of `depth` represents the number of steps needed to return to the main folder.