[3539. Find Sum of Array Product of Magical Sequences](https://leetcode.com/problems/find-sum-of-array-product-of-magical-sequences/)

# Intuition

* A magical sequence `seq` of length `m` is a sequence of indices in $[0..n-1]$.
* We consider the integer
  $S = 2^{\text{seq[0]}} + 2^{\text{seq[1]}} + \dots + 2^{\text{seq[m-1]}}.$
  The requirement is that the binary representation of `S` has exactly `k` one-bits (set bits).
* Every sequence contributes $nums[seq[0]] * ... * nums[seq[m-1]]$ to the answer; we sum these products over **all ordered** sequences of length `m` that satisfy the bit-count restriction.

We transform the problem from sequences to **counts**:

* Let r_i be how many times index `i` appears in `seq`. Then $(\sum_i r_i = m)$.
* The product contributed by all ordered sequences with that multiset of counts is
  $\frac{m!}{\prod_i r_i!} \times \prod_i nums[i]^{r_i},$
  because there are $m! / (∏ r_i!)$ permutations of the multiset, and each permutation's product is the same.
* So we need to iterate over all choices of nonnegative integers $r_0, r_1, ..., r_{n-1}$ that sum to `m` and such that the **binary sum**
  $\sum_i r_i \cdot 2^i$
  has exactly `k` set bits. For each valid count-vector we add the weighted product above.

Enumerating all count-vectors naively is infeasible, so we use a dynamic programming over indices that keeps track of:

* how many items `j` have been assigned so far,
* the current residual integer `p` equal to the lower bits we have after processing lower indices (this encodes carries), and
* `q` the number of ones already fixed in the low bit positions.

This DP uses the operation of shifting/resolving one bit position at a time:

* when we move from index `i` to `i+1`, the previously accumulated residual `p` is shifted right by one (this is the carry to the next higher bit), and the lowest bit of `p` contributes a 0/1 to the global bitcount `q`. Then we add $r_{i+1}$ copies at the new position which increases the residual.

The DP stores fractional counts divided by factorials (i.e., it stores contributions multiplied by $1/∏ r_i!$) - this makes transitions multiplicative by $numsPower[i][r] / r!$. At the end we multiply by `m!` to account for permutations.

---

## DP state and transition (precisely)

* Let `f[i][j][p][q]` be the sum (modulo `MOD`) of contributions (with division by product of factorials already applied) using the first `i+1` indices (`0..i`), assigning a total of `j` elements so far, with residual `p` after processing bits up to index `i`, and accumulated set bits `q` from lower positions.

* Residual `p` is an integer representing the current value of the partial binary sum restricted to a limited width; since $(r_i ≤ m)$, `p` never needs to exceed `2m` in practice (carry growth). We therefore cap `p` to range `0..2m`.

* Base:

  ```
  for j in 0..m:
      f[0][j][p=j][0] += nums[0]^j / j!
  ```

  This corresponds to placing `j` copies of index `0`. The residual at index 0 is `j` (no shifting yet) and no lower bits have been counted.

* Transition from `i` to `i+1`:

  * For a state `f[i][j][p][q]` consider placing `r` copies at index `i+1` (any `r ≥ 0` with `j + r ≤ m`).
  * When moving to the next bit position:

    * The lowest bit of `p` becomes a finished bit: `q2 = q + (p % 2)`.
    * The shifted residual becomes $floor(p / 2)$.
    * After adding `r` copies at the new index the new residual becomes `p2 = floor(p / 2) + r`.
  * The contribution multiplication factor is $nums[i+1]^r / r!$.
  * So:

    ```
    f[i+1][j+r][p2][q2] += f[i][j][p][q] * numsPower[i+1][r] / r!
    ```

* After processing all indices (`i = n-1`) we examine `f[n-1][m][p][q]`. The final number `S` has a bitcount equal to `q + bitcount(p)`. We accept those states where `q + bitcount(p) == k`. For each accepted state we add `f[n-1][m][p][q] * m!` to the result (we multiply by `m!` to undo the earlier division by $∏ r_i!$).

---

# Complexity

Let:

* `n = nums.length` (≤ 50),
* `m` (≤ 30),
* `k` (≤ 30).

DP table size: $(O(n \cdot m \cdot (2m) \cdot k) = O(n m^2 k))$. Each transition iterates `r` from `0` to `m`, so worst-case time is $(O(n \cdot m^3 \cdot k))$. With the problem limits this is feasible in compiled languages; the TypeScript/Node overhead may be substantial but still works for given bounds (m ≤ 30 keeps constants reasonable).

Memory wise the 4D table stores $(O(n m^2 k))$ `BigInt` entries - this is large but manageable given the limits used in typical judge environments (the example code uses BigInt to keep modular arithmetic correct).

---

# Code

The implementation below follows the DP. It uses `BigInt` and modulo arithmetic with $MOD = 10^9+7$. I preserved the combinatorial approach (precompute factorial and inverse factorial, precompute $nums[i]^r$ for each `r`) so transitions are fast.

> **Note:** TypeScript `BigInt` arithmetic is used throughout. On large DP arrays this can consume a lot of memory; depending on your environment you may need to optimize memory usage (for example by rolling the dimension `i`).

```ts
function magicalSum(m: number, k: number, nums: number[]): number {
  const n = nums.length;
  const MOD = 1000000007n;

  // factorials and inverse factorials (mod MOD) as BigInt
  const fac: bigint[] = new Array(m + 1).fill(1n);
  for (let i = 1; i <= m; i++) fac[i] = (fac[i - 1] * BigInt(i)) % MOD;

  const inv: bigint[] = new Array(m + 1).fill(1n);
  for (let i = 2; i <= m; i++) inv[i] = modInverse(BigInt(i), MOD);
  const ifac: bigint[] = new Array(m + 1).fill(1n);
  ifac[0] = 1n;
  for (let i = 1; i <= m; i++) ifac[i] = (ifac[i - 1] * inv[i]) % MOD; // 1/i!

  // Precompute powers nums[i]^r mod MOD
  const numsPower: bigint[][] = new Array(n);
  for (let i = 0; i < n; i++) {
    numsPower[i] = new Array(m + 1).fill(1n);
    for (let r = 1; r <= m; r++) numsPower[i][r] = (numsPower[i][r - 1] * BigInt(nums[i])) % MOD;
  }

  // DP array f[i][j][p][q] : to save memory we can keep "i" rolling
  const maxP = m * 2;
  // We'll use two layers for i: cur and next
  // Dimensions: j=0..m, p=0..maxP, q=0..k
  function makeLayer() {
    const layer: bigint[][][] = new Array(m + 1);
    for (let j = 0; j <= m; j++) {
      layer[j] = new Array(maxP + 1);
      for (let p = 0; p <= maxP; p++) {
        layer[j][p] = new Array(k + 1).fill(0n);
      }
    }
    return layer;
  }

  // Initialize for i=0
  let cur = makeLayer();
  for (let j = 0; j <= m; j++) {
    // f[0][j][p=j][q=0] = numsPower[0][j] / j!
    cur[j][j][0] = (numsPower[0][j] * ifac[j]) % MOD;
  }

  // iterate i from 0..n-2
  for (let i = 0; i + 1 < n; i++) {
    const nxt = makeLayer();

    for (let j = 0; j <= m; j++) {
      for (let p = 0; p <= maxP; p++) {
        for (let q = 0; q <= k; q++) {
          const val = cur[j][p][q];
          if (val === 0n) continue;

          // lowest bit of p contributes to bitcount
          const qBase = q + (p & 1);
          if (qBase > k) continue;

          // try adding r copies at index i+1
          for (let r = 0; r + j <= m; r++) {
            const p2 = Math.floor(p / 2) + r;
            if (p2 > maxP) break;
            const q2 = qBase;
            // multiply by numsPower[i+1][r] / r!
            const add = (((val * numsPower[i + 1][r]) % MOD) * ifac[r]) % MOD;
            nxt[j + r][p2][q2] = (nxt[j + r][p2][q2] + add) % MOD;
          }
        }
      }
    }

    cur = nxt; // roll
  }

  // Summation: states with j==m and bitcount(p)+q == k
  let res = 0n;
  for (let p = 0; p <= maxP; p++) {
    for (let q = 0; q <= k; q++) {
      if (popcount(p) + q === k) {
        res = (res + (cur[m][p][q] * fac[m]) % MOD) % MOD;
      }
    }
  }

  return Number(res);

  // helper: modular inverse (Fermat)
  function modInverse(a: bigint, mod: bigint): bigint {
    return modPow(a, mod - 2n, mod);
  }

  function modPow(x: bigint, y: bigint, mod: bigint): bigint {
    let res = 1n;
    let base = x % mod;
    while (y > 0n) {
      if ((y & 1n) === 1n) res = (res * base) % mod;
      base = (base * base) % mod;
      y >>= 1n;
    }
    return res;
  }

  function popcount(x: number): number {
    let c = 0;
    while (x > 0) {
      c += x & 1;
      x >>>= 1;
    }
    return c;
  }
};

```

---

## Example walkthrough

Take Example 2 from the prompt:

```
m = 2, k = 2, nums = [5,4,3,2,1].
```

* All ordered sequences of length 2 whose sum of $2^{idx}$ has bitcount 2 are exactly the ordered pairs of distinct indices `(i,j)` (because $2^i + 2^j$ has two 1-bits if `i != j`). There are `n*(n-1)` such ordered pairs. Each pair `(i,j)` contributes `nums[i]*nums[j]`.
* Summing all products over ordered distinct pairs equals: for each i, $nums[i] * (sum_{j != i} nums[j])$. The DP computes this by counting distributions $r_i$ (with $r_i$ in {0,1,2}, sum=2) and counting only those with no carries that reduce bitcount < 2.
* The DP and combinatorics above produce the same final value `170` (as the example).

---
